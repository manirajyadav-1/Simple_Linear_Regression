{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**1. Implement Linear Regression and calculate sum of residual error on the following\n",
        "Datasets.\n",
        "x = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
        "y = [1, 3, 2, 5, 7, 8, 8, 9, 10, 12]\n",
        "-Compute the regression coefficients using analytic formulation and calculate Sum\n",
        "Squared Error (SSE) and R 2 value.\n",
        "-Implement gradient descent (both Full-batch and Stochastic with stopping\n",
        "criteria) on Least Mean Square loss formulation to compute the coefficients of\n",
        "regression matrix and compare the results using performance measures such as R 2\n",
        "SSE etc.**"
      ],
      "metadata": {
        "id": "WXZJ75WHz3jl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6g5bzfGNzwR9",
        "outputId": "5d9a545a-dfd0-473d-bef2-fa78f354f786"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analytical Solution:\n",
            "B0: 1.2363636363636363, B1: 1.1696969696969697\n",
            "SSE: 5.624242424242423, R²: 0.952538038613988\n",
            "\n",
            "Full-batch Gradient Descent:\n",
            "B0: 1.2328099487610318, B1: 1.170263693076768\n",
            "SSE: 5.624278989977716, R²: 0.9525377300423822\n",
            "\n",
            "Stochastic Gradient Descent:\n",
            "B0: 0.8967040680508923, B1: 1.2986755729435908\n",
            "SSE: 7.576246971879953, R²: 0.9360654263976376\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Data\n",
        "X = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
        "Y = np.array([1, 3, 2, 5, 7, 8, 8, 9, 10, 12])\n",
        "\n",
        "# Analytical solution\n",
        "def analytical_solution(X, Y):\n",
        "    n = len(X)\n",
        "    X_mean = np.mean(X)\n",
        "    Y_mean = np.mean(Y)\n",
        "\n",
        "    # Calculate the coefficients\n",
        "    B1 = np.sum((X - X_mean) * (Y - Y_mean)) / np.sum((X - X_mean) ** 2)\n",
        "    B0 = Y_mean - B1 * X_mean\n",
        "    return B0, B1\n",
        "\n",
        "# Predict function\n",
        "def predict(X, B0, B1):\n",
        "    return B0 + B1 * X\n",
        "\n",
        "# Sum of Squared Errors (SSE)\n",
        "def calculate_sse(Y_true, Y_pred):\n",
        "    return np.sum((Y_true - Y_pred) ** 2)\n",
        "\n",
        "# Coefficient of Determination (R²)\n",
        "def calculate_r2(Y_true, Y_pred):\n",
        "    ss_total = np.sum((Y_true - np.mean(Y_true)) ** 2)\n",
        "    ss_residual = np.sum((Y_true - Y_pred) ** 2)\n",
        "    return 1 - (ss_residual / ss_total)\n",
        "\n",
        "# Full-batch Gradient Descent\n",
        "def full_batch_gradient_descent(X, Y, alpha=0.01, epochs=1000):\n",
        "    m = len(Y)\n",
        "    B0 = B1 = 0\n",
        "    for _ in range(epochs):\n",
        "        Y_pred = B0 + B1 * X\n",
        "        d_B0 = -(2/m) * np.sum(Y - Y_pred)\n",
        "        d_B1 = -(2/m) * np.sum((Y - Y_pred) * X)\n",
        "        B0 -= alpha * d_B0\n",
        "        B1 -= alpha * d_B1\n",
        "    return B0, B1\n",
        "\n",
        "# Stochastic Gradient Descent\n",
        "def stochastic_gradient_descent(X, Y, alpha=0.01, epochs=1000):\n",
        "    m = len(Y)\n",
        "    B0 = B1 = 0\n",
        "    for _ in range(epochs):\n",
        "        for i in range(m):\n",
        "            Y_pred = B0 + B1 * X[i]\n",
        "            d_B0 = -(2) * (Y[i] - Y_pred)\n",
        "            d_B1 = -(2) * (Y[i] - Y_pred) * X[i]\n",
        "            B0 -= alpha * d_B0\n",
        "            B1 -= alpha * d_B1\n",
        "    return B0, B1\n",
        "\n",
        "# Compute regression coefficients using analytical solution\n",
        "B0_analytical, B1_analytical = analytical_solution(X, Y)\n",
        "Y_pred_analytical = predict(X, B0_analytical, B1_analytical)\n",
        "\n",
        "# Compute SSE and R² for analytical solution\n",
        "SSE_analytical = calculate_sse(Y, Y_pred_analytical)\n",
        "R2_analytical = calculate_r2(Y, Y_pred_analytical)\n",
        "\n",
        "# Compute regression coefficients using Full-batch Gradient Descent\n",
        "B0_full_gd, B1_full_gd = full_batch_gradient_descent(X, Y)\n",
        "Y_pred_full_gd = predict(X, B0_full_gd, B1_full_gd)\n",
        "\n",
        "# Compute SSE and R² for Full-batch Gradient Descent\n",
        "SSE_full_gd = calculate_sse(Y, Y_pred_full_gd)\n",
        "R2_full_gd = calculate_r2(Y, Y_pred_full_gd)\n",
        "\n",
        "# Compute regression coefficients using Stochastic Gradient Descent\n",
        "B0_sgd, B1_sgd = stochastic_gradient_descent(X, Y)\n",
        "Y_pred_sgd = predict(X, B0_sgd, B1_sgd)\n",
        "\n",
        "# Compute SSE and R² for Stochastic Gradient Descent\n",
        "SSE_sgd = calculate_sse(Y, Y_pred_sgd)\n",
        "R2_sgd = calculate_r2(Y, Y_pred_sgd)\n",
        "\n",
        "print(\"Analytical Solution:\")\n",
        "print(f\"B0: {B0_analytical}, B1: {B1_analytical}\")\n",
        "print(f\"SSE: {SSE_analytical}, R²: {R2_analytical}\\n\")\n",
        "\n",
        "print(\"Full-batch Gradient Descent:\")\n",
        "print(f\"B0: {B0_full_gd}, B1: {B1_full_gd}\")\n",
        "print(f\"SSE: {SSE_full_gd}, R²: {R2_full_gd}\\n\")\n",
        "\n",
        "print(\"Stochastic Gradient Descent:\")\n",
        "print(f\"B0: {B0_sgd}, B1: {B1_sgd}\")\n",
        "print(f\"SSE: {SSE_sgd}, R²: {R2_sgd}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Download Boston Housing Rate Dataset. Analyse the input attributes and find out the attribute that best follow the linear relationship with the output price. Implement both the analytic formulation and gradient descent (Full-batch, stochastic) on LMS loss formulation to compute the coefficients of regression matrix and compare the results.**\n"
      ],
      "metadata": {
        "id": "aYQtte_L4_nM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load the dataset\n",
        "dataset_path = '/content/drive/MyDrive/Colab Notebooks/Data/Boston.csv'\n",
        "data = pd.read_csv(dataset_path)\n",
        "data.head()\n",
        "\n",
        "# Splitting the data into input features and target variable\n",
        "X_features = data.drop(columns='medv')  # Assuming 'medv' is the target column\n",
        "Y_target = data['medv']  # Target variable\n",
        "\n",
        "# Analyzing Correlations\n",
        "correlations = X_features.corrwith(Y_target)\n",
        "\n",
        "# Print the correlation values for all attributes\n",
        "print(\"Correlation of each attribute with the target variable (Price):\")\n",
        "for attribute, correlation_value in correlations.items():\n",
        "    print(f\"{attribute}: {correlation_value:.4f}\")\n",
        "\n",
        "# Identify the attribute with the highest correlation to the target variable\n",
        "best_feature = correlations.idxmax()\n",
        "print(f\"\\nAttribute with the highest correlation to medv: {best_feature}, Correlation: {correlations.max():.4f}\")\n",
        "\n",
        "# Selecting the best attribute for Simple Linear Regression\n",
        "X_selected = X_features[[best_feature]].values.flatten()\n",
        "Y_selected = Y_target.values\n",
        "\n",
        "# Analytical solution\n",
        "def analytical_solution(X, Y):\n",
        "    n = len(X)\n",
        "    X_mean = np.mean(X)\n",
        "    Y_mean = np.mean(Y)\n",
        "    # Calculate the coefficients\n",
        "    W1 = np.sum((X - X_mean) * (Y - Y_mean)) / np.sum((X - X_mean) ** 2)\n",
        "    W0 = Y_mean - W1 * X_mean\n",
        "    return W0, W1\n",
        "\n",
        "# Predict function\n",
        "def predict(X, W0, W1):\n",
        "    return W0 + W1 * X\n",
        "\n",
        "# Sum of Squared Errors (SSE)\n",
        "def calculate_sse(Y_true, Y_pred):\n",
        "    return np.sum((Y_true - Y_pred) ** 2)\n",
        "\n",
        "# Coefficient of Determination (R²)\n",
        "def calculate_r2(Y_true, Y_pred):\n",
        "    ss_total = np.sum((Y_true - np.mean(Y_true)) ** 2)\n",
        "    ss_residual = np.sum((Y_true - Y_pred) ** 2)\n",
        "    return 1 - (ss_residual / ss_total)\n",
        "\n",
        "# Full-batch Gradient Descent\n",
        "def full_batch_gradient_descent(X, Y, alpha=0.01, epochs=1000):\n",
        "    m = len(Y)\n",
        "    W0 = W1 = 0\n",
        "    for _ in range(epochs):\n",
        "        Y_pred = W0 + W1 * X\n",
        "        d_W0 = -(2/m) * np.sum(Y - Y_pred)\n",
        "        d_W1 = -(2/m) * np.sum((Y - Y_pred) * X)\n",
        "        W0 -= alpha * d_W0\n",
        "        W1 -= alpha * d_W1\n",
        "    return W0, W1\n",
        "\n",
        "# Stochastic Gradient Descent\n",
        "def stochastic_gradient_descent(X, Y, alpha=0.01, epochs=1000):\n",
        "    m = len(Y)\n",
        "    W0 = W1 = 0\n",
        "    for _ in range(epochs):\n",
        "        for i in range(m):\n",
        "            Y_pred = W0 + W1 * X[i]\n",
        "            d_W0 = -(2) * (Y[i] - Y_pred)\n",
        "            d_W1 = -(2) * (Y[i] - Y_pred) * X[i]\n",
        "            W0 -= alpha * d_W0\n",
        "            W1 -= alpha * d_W1\n",
        "    return W0, W1\n",
        "\n",
        "# Compute regression coefficients using analytical solution\n",
        "W0_analytical, W1_analytical = analytical_solution(X_selected, Y_selected)\n",
        "Y_pred_analytical = predict(X_selected, W0_analytical, W1_analytical)\n",
        "\n",
        "# Compute SSE and R² for analytical solution\n",
        "SSE_analytical = calculate_sse(Y_selected, Y_pred_analytical)\n",
        "R2_analytical = calculate_r2(Y_selected, Y_pred_analytical)\n",
        "\n",
        "# Compute regression coefficients using Full-batch Gradient Descent\n",
        "W0_full_gd, W1_full_gd = full_batch_gradient_descent(X_selected, Y_selected)\n",
        "Y_pred_full_gd = predict(X_selected, W0_full_gd, W1_full_gd)\n",
        "\n",
        "# Compute SSE and R² for Full-batch Gradient Descent\n",
        "SSE_full_gd = calculate_sse(Y_selected, Y_pred_full_gd)\n",
        "R2_full_gd = calculate_r2(Y_selected, Y_pred_full_gd)\n",
        "\n",
        "# Compute regression coefficients using Stochastic Gradient Descent\n",
        "W0_sgd, W1_sgd = stochastic_gradient_descent(X_selected, Y_selected)\n",
        "Y_pred_sgd = predict(X_selected, W0_sgd, W1_sgd)\n",
        "\n",
        "# Compute SSE and R² for Stochastic Gradient Descent\n",
        "SSE_sgd = calculate_sse(Y_selected, Y_pred_sgd)\n",
        "R2_sgd = calculate_r2(Y_selected, Y_pred_sgd)\n",
        "\n",
        "# Print results\n",
        "print(\"Analytical Solution:\")\n",
        "print(f\"W0: {W0_analytical}, W1: {W1_analytical}\")\n",
        "print(f\"SSE: {SSE_analytical}, R²: {R2_analytical}\\n\")\n",
        "\n",
        "print(\"Full-batch Gradient Descent:\")\n",
        "print(f\"W0: {W0_full_gd}, W1: {W1_full_gd}\")\n",
        "print(f\"SSE: {SSE_full_gd}, R²: {R2_full_gd}\\n\")\n",
        "\n",
        "print(\"Stochastic Gradient Descent:\")\n",
        "print(f\"W0: {W0_sgd}, W1: {W1_sgd}\")\n",
        "print(f\"SSE: {SSE_sgd}, R²: {R2_sgd}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBlcLtoZ1Zkn",
        "outputId": "b27c3264-a8d6-454a-dbed-262c2f73fdd2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correlation of each attribute with the target variable (Price):\n",
            "Unnamed: 0: -0.2266\n",
            "crim: -0.3883\n",
            "zn: 0.3604\n",
            "indus: -0.4837\n",
            "chas: 0.1753\n",
            "nox: -0.4273\n",
            "rm: 0.6954\n",
            "age: -0.3770\n",
            "dis: 0.2499\n",
            "rad: -0.3816\n",
            "tax: -0.4685\n",
            "ptratio: -0.5078\n",
            "black: 0.3335\n",
            "lstat: -0.7377\n",
            "\n",
            "Attribute with the highest correlation to medv: rm, Correlation: 0.6954\n",
            "Analytical Solution:\n",
            "W0: -34.67062077643857, W1: 9.10210898118031\n",
            "SSE: 22061.879196211798, R²: 0.48352545599133423\n",
            "\n",
            "Full-batch Gradient Descent:\n",
            "W0: -6.970943890333078, W1: 4.747579345988098\n",
            "SSE: 26845.286348783786, R²: 0.37154460404484113\n",
            "\n",
            "Stochastic Gradient Descent:\n",
            "W0: -12.007290075470893, W1: 4.230467524569683\n",
            "SSE: 59984.42950939596, R²: -0.40425167788085914\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KzNmITvs56E8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}